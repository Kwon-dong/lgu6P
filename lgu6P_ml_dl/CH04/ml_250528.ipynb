{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d73709-d191-4fa9-bf77-cb216b54931c",
   "metadata": {},
   "source": [
    "# 교차 검증, 하이퍼파라미터 튜닝\n",
    "- 가장 좋은 모델 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3876e8d7-3aea-4283-9fe0-8aefb7e2ba55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    549\n",
       "1    342\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd  # 데이터 처리를 위한 pandas\n",
    "import numpy as np   # 수치 계산을 위한 numpy\n",
    "from sklearn.ensemble import RandomForestClassifier  # 랜덤 포레스트 분류기\n",
    "from sklearn.svm import SVC  # 서포트 벡터 머신\n",
    "from sklearn.linear_model import LogisticRegression  # 로지스틱 회귀\n",
    "from sklearn.model_selection import train_test_split, cross_val_score  # 데이터 분할 및 교차 검증\n",
    "from sklearn.metrics import accuracy_score  # 정확도 평가 지표\n",
    "\n",
    "# 데이터 가져오기\n",
    "data = pd.read_csv('train.csv')\n",
    "data.head()\n",
    "\n",
    "# 모델링에 사용할 특성(feature)과 타겟(target) 변수 선택\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']  # 승객 등급, 성별, 나이, 동반자 수, 요금, 탑승 항구\n",
    "target = 'Survived'  # 생존 여부 (0: 사망, 1: 생존)\n",
    "data['Survived'].value_counts()  # 0과 1의 비율이 5:5는 아님 => 클래스 불균형(Class Imbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44111c33-c041-466d-9559-3ad11b82b002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "print(data.isnull().sum())\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d043c941-c9b4-4cda-8955-a7a20a2d7e63",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n",
    "- 고려사항\n",
    "  + 전처리를 전체 데이터에 해도 무방한가? 아니면 훈련데이터에만 적용해야 하는가?\n",
    "  + 범주형 데이터는 2가지 선택지가 존재 : 1) One-Hot Encoder (= 동일 가중치 부여) 2) Label Encoder (0, 1, 2)\n",
    "  + Label Encoder 사용하는 경우 => 탐색적 데이터 분석 & 사회적인 통념을 고려해서 전처리\n",
    "    - ex) 타이타닉 여성 생존자가 남성보다 많음 (레이디 퍼스트 문화) => 아래처럼 여성=1로 여성에게 더 높은 가중치 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7b88bd5-a3ab-422b-9c3b-fb8ff6522ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['Sex'].unique()\n",
    "data['Sex'] = data['Sex'].map({'male' : 0, 'female' : 1})  # 남성=0, 여성=1\n",
    "data['Embarked'] = data['Embarked'].map({'C' : 0, 'Q' : 1, 'S' : 2})  # 타이타닉 C 칸에서 사망자 많음 => 가중치 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80cdfae4-46d5-40a3-8e39-1a89b280501c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked\n",
       "2.0    644\n",
       "0.0    168\n",
       "1.0     77\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1c438b-c6c2-4c28-a25e-0c7e486c3e35",
   "metadata": {},
   "source": [
    "# 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "113137c0-6dda-4604-816d-39b2359d4972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((668, 7), (223, 7), (668,), (223,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아래의 features에서 고려하지 않은 feature(= 학습에 이용하지 않는 독립변수) 3개 : ID, Name, Cabin \n",
    "# ID, Name 제거 이유 : 패턴이 발견되지 않는 변수는 제외\n",
    "# Cabin 제거 이유 : 결측치의 개수가 너무 많아서 제외\n",
    "# 참고 자료 : https://scikit-learn.org/stable/modules/impute.html\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']  # 승객 등급, 성별, 나이, 동반자 수, 요금, 탑승 항구\n",
    "target = 'Survived' \n",
    "\n",
    "X = data[features]  # 독립 변수\n",
    "y = data[target]    # 종속 변수\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, stratify=y    # test_size default값 : 75/25\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f362ca24-e454-441c-8eec-4d771a48dc9e",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "509c01bf-5fd6-4237-b2bf-6b9fd91191fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 668 entries, 486 to 821\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    668 non-null    int64  \n",
      " 1   Sex       668 non-null    int64  \n",
      " 2   Age       537 non-null    float64\n",
      " 3   SibSp     668 non-null    int64  \n",
      " 4   Parch     668 non-null    int64  \n",
      " 5   Fare      668 non-null    float64\n",
      " 6   Embarked  666 non-null    float64\n",
      "dtypes: float64(3), int64(4)\n",
      "memory usage: 41.8 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "154dd91a-6cde-418c-935b-4b2fa46ee27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0 2.0\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터의 정보를 이용해서 테스트 테이터에 적용\n",
    "# 훈련데이터에서 결측치를 채울 대표값 계산\n",
    "age_mean = round(X_train['Age'].mean(), 0)     # 승객 나이의 평균값        \n",
    "embarked_mode = X_train['Embarked'].mode()[0]  # 탑승 항구의 최빈값\n",
    "fare_mean = X_train['Fare'].mean()             # 요금의 평균값\n",
    "pclass_mode = X_train['Pclass'].mode()[0]      # 승객 등급의 최빈값\n",
    "\n",
    "\n",
    "print(age_mean, embarked_mode)\n",
    "\n",
    "# 훈련데이터 적용\n",
    "X_train['Age'] = X_train['Age'].fillna(age_mean)\n",
    "X_train['Embarked'] = X_train['Embarked'].fillna(embarked_mode)\n",
    "\n",
    "# 테스트 데이터 적용\n",
    "X_test['Age'] = X_test['Age'].fillna(age_mean)\n",
    "X_test['Embarked'] = X_test['Embarked'].fillna(embarked_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c47625b-3c63-4335-b2ae-e4dc835d8d98",
   "metadata": {},
   "source": [
    "- 정규화, 표준화, One-Hot Encoding 고려해야 하나, 여기서는 안함\n",
    "  + 이유 : 연속형 데이터로 볼만한 것이 없음 => 대부분이 이산형 데이터(Count 데이터)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1d8a9d-bb77-4e26-bad5-aa9a0713a7ea",
   "metadata": {},
   "source": [
    "# 모델링\n",
    "- 각 모델 별 하이퍼파라미터 후보군 정의\n",
    "- 교차 검증\n",
    "- 가장 최고의 모델을 선정\n",
    "  + 여러 모델 참고 자료 : https://scikit-learn.org/stable/modules/ensemble.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd943b9c-c4a1-4b64-a495-4fca1759d7d2",
   "metadata": {},
   "source": [
    "- Decision Tree는 부등호로 구분\n",
    "  + Gini, Entropy로 독립변수 구분\n",
    "- RandomForest : Decision Tree의 확장판\n",
    "  + tree1 : 사망\n",
    "  + tree2 : 생존\n",
    "  + tree3 : 사망\n",
    "  + 결론 : 사망2/생존1 이니까, 이 모델은 사망으로 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a752722a-0f7a-48e2-88c4-9d9464a63950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing RandomForest ---\n",
      "Params: {'n_estimators': 100, 'max_depth': None}, CV Accuracy: 0.8249\n",
      "Params: {'n_estimators': 200, 'max_depth': 5}, CV Accuracy: 0.8264\n",
      "\n",
      "--- Testing SVM ---\n",
      "Params: {'C': 1.0, 'kernel': 'rbf'}, CV Accuracy: 0.6931\n",
      "Params: {'C': 0.5, 'kernel': 'linear'}, CV Accuracy: 0.7934\n",
      "\n",
      "--- Testing LogisticRegression ---\n",
      "Params: {'C': 1.0, 'max_iter': 1000}, CV Accuracy: 0.8024\n",
      "Params: {'C': 0.1, 'max_iter': 1000}, CV Accuracy: 0.8084\n",
      "\n",
      "Best Model: RandomForest\n",
      "Best CV Score: 0.8264\n",
      "Test Set Accuracy: 0.7758\n"
     ]
    }
   ],
   "source": [
    "# 사용할 모델 정의\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),   # 랜덤 포레스트 분류기\n",
    "    'SVM': SVC(random_state=42, probability=True),             # 서포트 벡터 머신 (선형 모델 but, 현재는 퍼셉트론 모델을 주로 사용)\n",
    "    'LogisticRegression': LogisticRegression(random_state=42)  # 로지스틱 회귀\n",
    "}\n",
    "\n",
    "# 각 모델별 하이퍼파라미터 후보군 정의\n",
    "param_grid = {\n",
    "    'RandomForest': [\n",
    "        {'n_estimators': 100, 'max_depth': None},  # 트리 100개, 깊이 제한 없음\n",
    "        {'n_estimators': 200, 'max_depth': 5}      # 트리 200개, 최대 깊이 5\n",
    "    ],\n",
    "    'SVM': [\n",
    "        {'C': 1.0, 'kernel': 'rbf'},    # RBF 커널, C=1.0\n",
    "        {'C': 0.5, 'kernel': 'linear'}  # 선형 커널, C=0.5\n",
    "    ],\n",
    "    'LogisticRegression': [\n",
    "        {'C': 1.0, 'max_iter': 1000},  # 기본 설정\n",
    "        {'C': 0.1, 'max_iter': 1000}   # 더 강한 정규화\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 교차 검증을 통한 최적 모델 선정\n",
    "best_score = 0          # 최고 성능 점수\n",
    "best_model_name = None  # 최고 성능 모델 이름\n",
    "best_model = None       # 최고 성능 모델 객체\n",
    "\n",
    "\n",
    "# 각 모델과 하이퍼파라미터 조합에 대해 교차 검증 수행\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n--- Testing {model_name} ---\")\n",
    "    for params in param_grid[model_name]:\n",
    "        model.set_params(**params)  # 하이퍼파라미터 설정\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')  # 5-fold 교차검증\n",
    "        mean_cv = np.mean(cv_scores)  # 평균 교차검증 점수\n",
    "        print(f\"Params: {params}, CV Accuracy: {mean_cv:.4f}\")\n",
    "        \n",
    "        # 최고 성능 모델 업데이트\n",
    "        if mean_cv > best_score:\n",
    "            best_score = mean_cv\n",
    "            best_model_name = model_name\n",
    "            best_model = model.set_params(**params)\n",
    "\n",
    "# 최종 선택된 모델로 테스트셋 평가\n",
    "best_model.fit(X_train, y_train)  # 최적 모델 학습\n",
    "y_pred = best_model.predict(X_test)  # 테스트셋 예측\n",
    "test_acc = accuracy_score(y_test, y_pred)  # 테스트셋 정확도 계산\n",
    "\n",
    "# 최종 결과 출력\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Best CV Score: {best_score:.4f}\")\n",
    "print(f\"Test Set Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf8a2b26-23a1-49eb-9ffc-f551e7fc04c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing RandomForest ---\n",
      "Params: {'n_estimators': 100, 'max_depth': None}, CV Accuracy: 0.8249, Time: 0.68 sec\n",
      "Params: {'n_estimators': 200, 'max_depth': 5}, CV Accuracy: 0.8264, Time: 1.20 sec\n",
      "\n",
      "--- Testing SVM ---\n",
      "Params: {'C': 1.0, 'kernel': 'rbf'}, CV Accuracy: 0.6931, Time: 0.24 sec\n",
      "Params: {'C': 0.5, 'kernel': 'linear'}, CV Accuracy: 0.7934, Time: 76.87 sec\n",
      "\n",
      "--- Testing LogisticRegression ---\n",
      "Params: {'C': 1.0, 'max_iter': 1000}, CV Accuracy: 0.8024, Time: 0.11 sec\n",
      "Params: {'C': 0.1, 'max_iter': 1000}, CV Accuracy: 0.8084, Time: 0.11 sec\n",
      "\n",
      "Best Model: RandomForest\n",
      "Best CV Score: 0.8264\n",
      "Test Set Accuracy: 0.7758\n",
      "Best Model Cross-Validation Time: 1.20 sec\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증에 걸린 시간까지 계산한 코드\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 사용할 모델 정의\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'LogisticRegression': LogisticRegression(random_state=42)\n",
    "}\n",
    "\n",
    "# 각 모델별 하이퍼파라미터 후보군 정의\n",
    "param_grid = {\n",
    "    'RandomForest': [\n",
    "        {'n_estimators': 100, 'max_depth': None},\n",
    "        {'n_estimators': 200, 'max_depth': 5}\n",
    "    ],\n",
    "    'SVM': [\n",
    "        {'C': 1.0, 'kernel': 'rbf'},\n",
    "        {'C': 0.5, 'kernel': 'linear'}\n",
    "    ],\n",
    "    'LogisticRegression': [\n",
    "        {'C': 1.0, 'max_iter': 1000},\n",
    "        {'C': 0.1, 'max_iter': 1000}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 결과 저장 변수 초기화\n",
    "best_score = 0\n",
    "best_model_name = None\n",
    "best_model = None\n",
    "best_cv_time = 0  # 최적 모델의 CV 수행 시간 저장용\n",
    "\n",
    "# 각 모델과 하이퍼파라미터 조합에 대해 교차 검증 수행\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n--- Testing {model_name} ---\")\n",
    "    \n",
    "    for params in param_grid[model_name]:\n",
    "        model.set_params(**params)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        end_time = time.time()\n",
    "        \n",
    "        mean_cv = np.mean(cv_scores)\n",
    "        elapsed = end_time - start_time\n",
    "        \n",
    "        print(f\"Params: {params}, CV Accuracy: {mean_cv:.4f}, Time: {elapsed:.2f} sec\")\n",
    "        \n",
    "        if mean_cv > best_score:\n",
    "            best_score = mean_cv\n",
    "            best_model_name = model_name\n",
    "            best_model = model.set_params(**params)\n",
    "            best_cv_time = elapsed  # 여기서 최적 모델의 CV 시간 저장\n",
    "\n",
    "# 최종 선택된 모델로 테스트셋 평가\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# 최종 결과 출력\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Best CV Score: {best_score:.4f}\")\n",
    "print(f\"Test Set Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Best Model Cross-Validation Time: {best_cv_time:.2f} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705827ba-790c-4070-8481-a9d0816fd2b7",
   "metadata": {},
   "source": [
    "# 전처리 정보 저장 & 모델 저장해서 내보내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "666bb5af-b92d-4938-a2f2-073becbc70a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model: RandomForest\n",
      "Best CV Score: 0.8264\n",
      "Test Set Accuracy: 0.7758\n",
      "\n",
      "Model and preprocessing information have been saved.\n"
     ]
    }
   ],
   "source": [
    "import joblib   # 모델 저장을 위한 라이브러리\n",
    "import json     # 전처리 정보 저장을 위한 json\n",
    "\n",
    "# 전처리 정보 저장\n",
    "preprocessing_info = {\n",
    "    'age_mean': float(age_mean),\n",
    "    'fare_mean': float(fare_mean),\n",
    "    'pclass_mode': int(pclass_mode),\n",
    "    'embarked_mode': int(embarked_mode),\n",
    "    'features': features,\n",
    "    'sex_mapping': {'male': 0, 'female': 1},\n",
    "    'embarked_mapping': {'C': 0, 'Q': 1, 'S': 2}\n",
    "}\n",
    "\n",
    "# 모델과 전처리 정보 저장\n",
    "joblib.dump(best_model, 'titanic_model.joblib')\n",
    "\n",
    "# 훈련 데이터의 정보를 추가\n",
    "with open('preprocessing_info.json', 'w') as f:\n",
    "    json.dump(preprocessing_info, f)\n",
    "\n",
    "# 최종 결과 출력\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Best CV Score: {best_score:.4f}\")\n",
    "print(f\"Test Set Accuracy: {test_acc:.4f}\")\n",
    "print(\"\\nModel and preprocessing information have been saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc9381f-fead-4416-8053-ba0b652be6aa",
   "metadata": {},
   "source": [
    "- 전체 모델 만들기 복습 및 Predict Calorie Expenditure(CH03의 데이터) 캐글 대회 데이터에도 적용\n",
    "  + 코드 추가할 것 : 교차 검증 시, 시간 측정 하기\n",
    "  + 하이퍼파라미터 튜닝 개수를 늘릴 때마다 시간이 제법 많이 소요됨을 확인해봐라"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
